{
  "env": "humanoid_height_constrained",
  "alg": "ppo",
  "out_dir": "runs/metrics",
  "num_timesteps": 3000000,
  "episode_length": 1000,
  "num_envs": 1024,
  "unroll_length": 10,
  "batch_size": 512,
  "num_minibatches": 32,
  "num_updates_per_batch": 4,
  "learning_rate": 0.0003,
  "entropy_cost": 0.001,
  "discounting": 0.99,
  "reward_scaling": 1.0,
  "gae_lambda": 0.95,
  "clipping_epsilon": 0.3,
  "normalize_observations": true,
  "num_evals": 5,
  "num_eval_envs": 128,
  "deterministic_eval": false
}