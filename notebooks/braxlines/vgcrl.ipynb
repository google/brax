{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssCOanHc8JH_"
      },
      "source": [
        "# Training Goal-Conditioned and Unsupervised RL Agents in Brax\n",
        "\n",
        "In [Brax Training](https://colab.research.google.com/github/google/brax/blob/main/notebooks/training.ipynb) we tried out [gym](https://gym.openai.com/)-like environments and PPO, SAC, evolutionary search, and trajectory optimization algorithms. We can build various RL algorithms on top of these ultra-fast implementations. This colab runs a family of [variational GCRL](https://arxiv.org/abs/2106.01404) algorithms, which includes [goal-conditioned RL](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.51.3077) and [DIAYN](https://arxiv.org/abs/1802.06070) as special cases. Let's try it out!\n",
        "\n",
        "This provides a bare bone implementation based on minimal modifications to the\n",
        "baseline [PPO](https://github.com/google/brax/blob/main/brax/training/ppo.py),\n",
        "enabling training in a few minutes. More features, tunings, and benchmarked results will be added soon."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYe1kc3a4Oxc"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google/brax/blob/main/notebooks/braxlines/vgcrl.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlVNS8JstMRr"
      },
      "outputs": [],
      "source": [
        "#@title Colab setup and imports\n",
        "#@markdown ## ⚠️ PLEASE NOTE:\n",
        "#@markdown This colab runs best using a TPU runtime.  From the Colab menu, choose Runtime \u003e Change Runtime Type, then select **'TPU'** in the dropdown.\n",
        "\n",
        "from datetime import datetime\n",
        "import functools\n",
        "import os\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from IPython.display import HTML, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "  import brax\n",
        "except ImportError:\n",
        "  !pip install git+https://github.com/google/brax.git@main\n",
        "  clear_output()\n",
        "  import brax\n",
        "\n",
        "from brax.io import file as io_file\n",
        "from brax.io import html\n",
        "from brax.experimental.composer import composer\n",
        "from brax.experimental.braxlines.common import evaluators\n",
        "from brax.experimental.braxlines.common import logger_utils\n",
        "from brax.experimental.braxlines.training import ppo\n",
        "from brax.experimental.braxlines.vgcrl import evaluators as vgcrl_evaluators\n",
        "from brax.experimental.braxlines.vgcrl import utils as vgcrl_utils\n",
        "\n",
        "if \"COLAB_TPU_ADDR\" in os.environ:\n",
        "  from jax.tools import colab_tpu\n",
        "  colab_tpu.setup_tpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gh4QsRPnX770"
      },
      "outputs": [],
      "source": [
        "#@title Define experiment parameters\n",
        "\n",
        "#@markdown **Task Parameters**\n",
        "#@markdown \n",
        "#@markdown As in [DIAYN](https://arxiv.org/abs/1802.06070)\n",
        "#@markdown and [variational GCRL](https://arxiv.org/abs/2106.01404),\n",
        "#@markdown we assume some task knowledge about interesting dimensions\n",
        "#@markdown of the environment `obs_indices` defined by `env_space`.\n",
        "#@markdown This is also used for evaluation and visualization.\n",
        "#@markdown\n",
        "#@markdown When the **task parameters** are the same, the metrics computed by\n",
        "#@markdown [vgcrl/evaluators.py](https://github.com/google/brax/blob/main/brax/experimental/braxlines/vgcrl/evaluators.py)\n",
        "#@markdown are directly comparable across experiment runs with different\n",
        "#@markdown **experiment parameters**. \n",
        "env_name = 'ant'  # @param ['ant', 'halfcheetah', 'ant_cheetah', 'uni_ant', 'bi_ant']\n",
        "env_space = 'vel'  # @param ['vel', 'pos', 'ang']\n",
        "env_scale = 5.0 #@param{'type': 'number'}\n",
        "obs_indices = {\n",
        "    'vel': { # x-y velocity\n",
        "      'ant': (13, 14),\n",
        "      'humanoid': (22, 23),\n",
        "      'halfcheetah': (11,),\n",
        "      'uni_ant': (('vel:torso_ant1', 0),('vel:torso_ant1', 1)),\n",
        "      'bi_ant': (('vel:torso_ant1', 0),('vel:torso_ant2', 0)),\n",
        "    },\n",
        "    'ang': { # angular velocity\n",
        "      'ant': (17,),\n",
        "      'uni_ant': (('ang:torso_ant1', 2),),\n",
        "    },\n",
        "}[env_space][env_name]\n",
        "\n",
        "#@markdown **Experiment Parameters**\n",
        "#@markdown See below and [vgcrl/utils.py](https://github.com/google/brax/blob/main/brax/experimental/braxlines/vgcrl/utils.py)\n",
        "algo_name = 'diayn'  # @param ['gcrl', 'cdiayn', 'diayn', 'diayn_full', 'fixed_gcrl']\n",
        "logits_clip_range = 5.0  # @param {'type': 'number'}\n",
        "normalize_obs_for_disc = False  # @param {'type': 'boolean'}\n",
        "seed =   0# @param {type: 'integer'}\n",
        "diayn_num_skills = 8  # @param {type: 'integer'}\n",
        "output_path = None  # @param {'type': 'raw'}\n",
        "output_path = output_path.format(\n",
        "    date=datetime.now().strftime('%Y%m%d'),\n",
        "    env_space=env_space,\n",
        "    env_scale=env_scale,\n",
        "    env_name=env_name,\n",
        "    algo_name=algo_name) if output_path else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaJDZqhCLovU"
      },
      "outputs": [],
      "source": [
        "# @title Visualizing Brax environments\n",
        "# Create baseline environment to get observation specs\n",
        "base_env_fn = composer.create_fn(env_name=env_name)\n",
        "base_env = base_env_fn()\n",
        "env_obs_size = base_env.observation_size\n",
        "\n",
        "# Create discriminator-parameterized environment\n",
        "disc_fn = vgcrl_utils.create_disc_fn(algo_name=algo_name,\n",
        "                   observation_size=env_obs_size,\n",
        "                   obs_indices=obs_indices,\n",
        "                   scale=env_scale,\n",
        "                   diayn_num_skills = diayn_num_skills,\n",
        "                   logits_clip_range=logits_clip_range)\n",
        "disc = disc_fn(env=base_env, normalize_obs=normalize_obs_for_disc)\n",
        "extra_params = disc.init_model(rng=jax.random.PRNGKey(seed=seed))\n",
        "env_fn = vgcrl_utils.create_fn(env_name=env_name, disc=disc)\n",
        "\n",
        "# Visualize\n",
        "env = env_fn()\n",
        "jit_env_reset = jax.jit(env.reset)\n",
        "state = jit_env_reset(rng=jax.random.PRNGKey(seed=seed))\n",
        "clear_output()  # clear out jax.lax warning before rendering\n",
        "HTML(html.render(env.sys, [state.qp]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vgMSWODfyMC"
      },
      "outputs": [],
      "source": [
        "#@title Training\n",
        "num_timesteps_multiplier = 4  # @param {type: 'integer'}\n",
        "disc_update_ratio = 1.0  # @param {'type': 'number'}\n",
        "\n",
        "tab = logger_utils.Tabulator(output_path=f'{output_path}/training_curves.csv', append=False)\n",
        "\n",
        "# We determined some reasonable hyperparameters offline and share them here.\n",
        "n = num_timesteps_multiplier\n",
        "train_fn = functools.partial(\n",
        "    ppo.train,\n",
        "    num_timesteps=50_000_000 * n,\n",
        "    log_frequency=20,\n",
        "    reward_scaling=10,\n",
        "    episode_length=1000,\n",
        "    normalize_observations=True,\n",
        "    action_repeat=1,\n",
        "    unroll_length=5,\n",
        "    num_minibatches=32,\n",
        "    num_update_epochs=4,\n",
        "    discounting=0.95,\n",
        "    learning_rate=3e-4,\n",
        "    entropy_cost=1e-2,\n",
        "    num_envs=2048,\n",
        "    batch_size=1024)\n",
        "\n",
        "times = [datetime.now()]\n",
        "plotdata = {}\n",
        "plotkeys = ['eval/episode_reward', 'losses/disc_loss']\n",
        "\n",
        "def plot(output_path:str =None, output_name:str = 'training_curves'):\n",
        "  num_figs = len(plotkeys)\n",
        "  fig, axs = plt.subplots(ncols=num_figs, figsize=(3.5 * num_figs, 3))\n",
        "  for i, key in enumerate(plotkeys):\n",
        "    if key in plotdata:\n",
        "      axs[i].plot(plotdata[key]['x'], plotdata[key]['y'])\n",
        "    axs[i].set(xlabel='# environment steps', ylabel=key)\n",
        "    axs[i].set_xlim([0, train_fn.keywords['num_timesteps']])\n",
        "  fig.tight_layout()\n",
        "  if output_path:\n",
        "    with io_file.File(f'{output_path}/{output_name}.png', 'wb') as f:\n",
        "      plt.savefig(f)\n",
        "\n",
        "def progress(num_steps, metrics, _):\n",
        "  times.append(datetime.now())\n",
        "  for key, v in metrics.items():\n",
        "    plotdata[key] = plotdata.get(key, dict(x=[], y=[]))\n",
        "    plotdata[key]['x'] += [num_steps]\n",
        "    plotdata[key]['y'] += [v]\n",
        "  # the first step does not include losses\n",
        "  if num_steps \u003e 0:\n",
        "    tab.add(num_steps=num_steps, **metrics)\n",
        "    tab.dump()\n",
        "  clear_output(wait=True)\n",
        "  plot()\n",
        "  plt.show()\n",
        "\n",
        "extra_loss_fns = dict(disc_loss=disc.disc_loss_fn) if extra_params else None\n",
        "extra_loss_update_ratios = dict(\n",
        "    disc_loss=disc_update_ratio) if extra_params else None\n",
        "inference_fn, params, _ = train_fn(\n",
        "    environment_fn=env_fn,\n",
        "    progress_fn=progress,\n",
        "    extra_params=extra_params,\n",
        "    extra_loss_fns=extra_loss_fns,\n",
        "    extra_loss_update_ratios=extra_loss_update_ratios,\n",
        ")\n",
        "clear_output(wait=True)\n",
        "plot(output_path=output_path)\n",
        "\n",
        "print(f'time to jit: {times[1] - times[0]}')\n",
        "print(f'time to train: {times[-1] - times[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNMLEyaTspEM"
      },
      "outputs": [],
      "source": [
        "#@title Visualizing a trajectory of the learned inference function\n",
        "#@markdown If `z_value` is `None`, sample `z`, else fix `z` to `z_value`.\n",
        "z_value = 1  # @param {'type': 'raw'}\n",
        "eval_seed = 0  # @param {'type': 'integer'}\n",
        "\n",
        "z = {\n",
        "    'fixed_gcrl': jnp.ones(env.z_size) * z_value,\n",
        "    'gcrl': jnp.ones(env.z_size) * z_value,\n",
        "    'cdiayn': jnp.ones(env.z_size) * z_value,\n",
        "    'diayn': jax.nn.one_hot(jnp.array(int(z_value)), env.z_size),\n",
        "    'diayn_full': jax.nn.one_hot(jnp.array(int(z_value)), env.z_size),\n",
        "}[algo_name] if z_value is not None else None\n",
        "\n",
        "states = evaluators.visualize_env(\n",
        "    env_fn,\n",
        "    inference_fn,\n",
        "    params,\n",
        "    batch_size=0,\n",
        "    seed = eval_seed,\n",
        "    reset_args=(z,),\n",
        "    step_args=(params[0], params[-1],),\n",
        "    output_path=output_path,\n",
        "    output_name=f'video_z_{z_value}',\n",
        ")\n",
        "HTML(html.render(env.sys, [state.qp for state in states]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5eWOxg7RmQQ"
      },
      "outputs": [],
      "source": [
        "#@title Visualizing skills of the learned inference function in 2D plot\n",
        "num_samples_per_z = 5  # @param {type: 'integer'}\n",
        "time_subsampling = 10  # @param {type: 'integer'}\n",
        "time_last_n = 500 # @param {type: 'integer'}\n",
        "eval_seed = 0  # @param {type: 'integer'}\n",
        "\n",
        "vgcrl_evaluators.visualize_skills(\n",
        "    env_fn,\n",
        "    inference_fn,\n",
        "    obs_indices,\n",
        "    params,\n",
        "    env_scale,\n",
        "    algo_name,\n",
        "    output_path,\n",
        "    verbose=True,\n",
        "    num_samples_per_z=num_samples_per_z,\n",
        "    time_subsampling=time_subsampling,\n",
        "    time_last_n=time_last_n,\n",
        "    seed=eval_seed)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "name": "vgcrl.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1ZaAO4BS2tJ_03CIXdBCFibZR2yLl6dtv",
          "timestamp": 1629757558753
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
