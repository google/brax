{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google/brax/blob/to_torch/notebooks/pytorch.ipynb)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using Brax with Gym + PyTorch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Imports:\n",
    "import time\n",
    "import torch\n",
    "from functools import partial\n",
    "import time\n",
    "\n",
    "import gym\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from brax.envs.to_torch import JaxToTorchWrapper\n",
    "from brax.envs import _envs, create_gym_env\n",
    "\n",
    "COLAB = \"google.colab\" in str(get_ipython())\n",
    "\n",
    "if COLAB:\n",
    "    # Detect if running in Colab or not.\n",
    "    from jax.tools import colab_tpu\n",
    "    # configure jax to run on tpu:\n",
    "    colab_tpu.setup_tpu()\n",
    "\n",
    "# Registering the Brax envs in Gym (so we can use `gym.make` as usual):\n",
    "for env_name, env_class in _envs.items():\n",
    "    env_id = f\"brax_{env_name}-v0\"\n",
    "    entry_point = partial(create_gym_env, env_name=env_name)\n",
    "    if env_id not in gym.envs.registry.env_specs:\n",
    "        print(f\"Registring brax's '{env_name}' env under id '{env_id}'.\")\n",
    "        gym.register(env_id, entry_point=entry_point)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Benchmarking the performance of the Pytorch'ed Brax gym Env:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Number of parallel environments\n",
    "batch_size = 1024  #@param { type:\"slider\", min:0, max:4096, step: 1 }\n",
    "\n",
    "# Number of steps to take in the batched env.\n",
    "n_steps = 1000\n",
    "\n",
    "# Simple utility function for benchmarking.\n",
    "_times = [time.time()]\n",
    "def tick(name: str = \"\"):\n",
    "    _times.append(time.time())\n",
    "    elapsed = times[-1] - times[-2]\n",
    "    if name:\n",
    "        print(f\"Time for {name}: {elapsed}\")\n",
    "    return elapsed\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # BUG: (@lebrice): Getting a weird \"CUDA error: out of memory\" RuntimeError during\n",
    "    # JIT, which can be \"fixed\" by first creating a dummy cuda tensor!\n",
    "    v = torch.ones(1, device=\"cuda\")\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "env = gym.make(\"brax_halfcheetah-v0\", batch_size=batch_size)\n",
    "tick(\"Creating the env\")\n",
    "\n",
    "env = JaxToTorchWrapper(env)\n",
    "tick(\"Wrapping the env\")\n",
    "\n",
    "obs = env.reset()  # this can be relatively slow (~10 secs)\n",
    "tick(\"First reset\") \n",
    "\n",
    "obs, reward, done, info = env.step(env.action_space.sample())\n",
    "tick(\"First step\")  # this can be relatively slow (~10 secs)\n",
    "\n",
    "obs, reward, done, info = env.step(env.action_space.sample())\n",
    "tick(\"Second step\")  # this can be relatively slow (~10 secs)\n",
    "\n",
    "_times.clear()\n",
    "_times.append(time.time())\n",
    "\n",
    "# Create a Progress bar. NOTE: This Pbar effectively shows the step rate as well!\n",
    "pbar = tqdm.tqdm(range(n_steps), unit_scale=batch_size)\n",
    "for i in pbar:\n",
    "    # NOTE: Could use the `action_space` property like so even with CUDA, but we'd need\n",
    "    # to move the numpy array from CPU to GPU/TPU, which would kind-of defeat the\n",
    "    # purpose of this demo! Here we instead create a Tensor which is already on the GPU.\n",
    "    if not CUDA:\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        action = torch.rand(env.action_space.shape, device=\"cuda\") * 2 - 1\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    tick()\n",
    "\n",
    "\n",
    "elapsed_times = [times[i+1] - times[i] for i in range(len(times)-1)]\n",
    "\n",
    "time_for_n_steps_avg = np.mean(elapsed_times)\n",
    "time_for_n_steps_std = np.std(elapsed_times)\n",
    "\n",
    "frequency =  1 / time_for_n_steps_avg\n",
    "effective_frequency = (batch_size or 1) * frequency\n",
    "\n",
    "print(f\"Device used: {obs.device}\")\n",
    "print(f\"Number of parallel environments: {batch_size}\")\n",
    "print(f\"Average time per batched step:  {time_for_n_steps_avg} ± {time_for_n_steps_std} seconds\")\n",
    "print(f\"Frequency (after first two steps): ~{frequency:.3f} batched steps / second.\")\n",
    "print(f\"Effective Frequency (after first two steps): ~{effective_frequency:.3f} steps / second.\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time for Creating the env: 0.0038437843322753906\n",
      "Time for Wrapping the env: 0.0038437843322753906\n",
      "Time for First reset: 0.0038437843322753906\n",
      "Time for First step: 0.0038437843322753906\n",
      "Time for Second step: 0.0038437843322753906\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1024000/1024000 [00:03<00:00, 289150.23it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Device used: cuda:0\n",
      "Number of parallel environments: 1024\n",
      "Average time per batched step:  0.0039951517013366335 ± 0.00026153933497828803 seconds\n",
      "Frequency: ~250.303 batched steps / second.\n",
      "Effective Frequency: ~256310.668 steps / second.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('brax': conda)"
  },
  "interpreter": {
   "hash": "1812c2cdf0067f1c111fe8b907e8717aab013f923026de8fa0a048a0a07a7c66"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}