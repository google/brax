# Brax v0.14.0 Release Notes

* Support custom activation functions in checkpointing.
* Add value function coefficient to PPO.
* Pass through kernel initializers to SAC/PPO networks, and allow checkpointing of such parameters.
* Allow episode metrics during eval to be normalized by the episode length, as long as the metric name ends with "per_step".
* Add adaptive learning rate to PPO. Desired KL is sensitive to network initialization weights and entropy cost and may require some tuning for your environment.
* Add loss metrics to the PPO training logger.
* Add `donate_argnums` to brax PPO to somewhat mitigate repeated graph captures when using MJX-Warp.
* Add `normalize_observations_mode` to PPO to allow using EMA for running statistics instead of Welford. EMA is more stable for longer training runs.
* Fix bug in PPO training metric logging frequency for multi-GPU devices.
* Add value bootstrap on `timeout` for PPO. `reward += gamma * V(s) * time_out` if `bootstrap_on_timeout` is set to True.
* Add `clipping_epsilon_value` to PPO. If `clipping_epsilon_value` is not None, then we use a clipped value loss: `v_loss = max((vs - V(s))^2, (vs - clip(V(s), V_old(s) - epsilon, V_old(s) + epsilon))^2)`.
