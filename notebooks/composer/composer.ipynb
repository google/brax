{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssCOanHc8JH_"
      },
      "source": [
        "# Create Environments with Braxlines Composer\n",
        "\n",
        "[Braxlines Composer](https://github.com/google/brax/blob/main/brax/experimental/composer) allows modular composition of Brax environments. Let's try it out! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYe1kc3a4Oxc"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google/brax/blob/main/notebooks/braxlines/composer.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlVNS8JstMRr"
      },
      "outputs": [],
      "source": [
        "#@title Colab setup and imports\n",
        "#@markdown ## ⚠️ PLEASE NOTE:\n",
        "#@markdown This colab runs best using a TPU runtime.  From the Colab menu, choose Runtime \u003e Change Runtime Type, then select **'TPU'** in the dropdown.\n",
        "from datetime import datetime\n",
        "import functools\n",
        "import pprint\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from IPython.display import HTML, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "  import brax\n",
        "except ImportError:\n",
        "  !pip install git+https://github.com/google/brax.git@main\n",
        "  clear_output()\n",
        "  import brax\n",
        "\n",
        "from brax.io import html\n",
        "from brax.experimental.composer import composer\n",
        "from brax.experimental.composer import component_editor\n",
        "from brax.experimental.composer import register_default_components\n",
        "from brax.experimental.braxlines.common import evaluators\n",
        "from brax.experimental.braxlines.common import logger_utils\n",
        "from brax.experimental.braxlines.training import ppo\n",
        "register_default_components()\n",
        "\n",
        "if \"COLAB_TPU_ADDR\" in os.environ:\n",
        "  from jax.tools import colab_tpu\n",
        "  colab_tpu.setup_tpu()\n",
        "\n",
        "def show_env(env, mode):\n",
        "  if mode == 'print_obs':\n",
        "    pprint.pprint(composer.get_env_obs_dict_shape(env))\n",
        "  elif mode == 'print_sys':\n",
        "    pprint.pprint(env.unwrapped.composer.metadata.config_json)\n",
        "  else:\n",
        "    jit_env_reset = jax.jit(env.reset)\n",
        "    state = jit_env_reset(rng=jax.random.PRNGKey(seed=0))\n",
        "    clear_output(wait=True)\n",
        "    return HTML(html.render(env.sys, [state.qp]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1ZJ2jZDKH8Y"
      },
      "outputs": [],
      "source": [
        "#@title Create a custom env\n",
        "#@markdown See [env_descs.py](https://github.com/google/brax/blob/main/brax/experimental/composer/env_descs.py)\n",
        "#@markdown for more supported `env_name`.\n",
        "env_name = 'custom_ant_push' # @param ['custom_ant_push', 'ant_run', 'ant_chase', 'ant_push']\n",
        "mode = 'print_obs'# @param ['print_obs', 'print_sys', 'viewer']\n",
        "output_path = '' # @param {type: 'string'}\n",
        "if output_path:\n",
        "  output_path = f'{output_path}/{datetime.now().strftime(\"%Y%m%d\")}' \n",
        "  output_path = f'{output_path}/{env_name}'\n",
        "  print(f'Saving outputs to {output_path}')\n",
        "\n",
        "desc_edits = {\n",
        "    'components.cap1.reward_fns.goal.scale': 5,\n",
        "    'components.cap1.reward_fns.goal.target_goal': 5,\n",
        "}\n",
        "env_descs = {\n",
        "     'custom_ant_push':\n",
        "        dict(\n",
        "            components=dict(\n",
        "                ant1=dict(\n",
        "                    component='ant',\n",
        "                    pos=(0, 0, 0),\n",
        "                ),\n",
        "                cap1=dict(\n",
        "                    component='singleton',\n",
        "                    component_params=dict(size=0.5),\n",
        "                    pos=(1, 0, 0),\n",
        "                    observers=('root_z_joints',),\n",
        "                    reward_fns=dict(\n",
        "                        goal=dict(\n",
        "                            reward_type='root_goal',\n",
        "                            sdcomp='vel',\n",
        "                            indices=(0, 1),\n",
        "                            offset=5,\n",
        "                            scale=1,\n",
        "                            target_goal=4)),\n",
        "                    score_fns=dict(\n",
        "                        goal=dict(\n",
        "                            reward_type='root_goal',\n",
        "                            sdcomp='vel',\n",
        "                            indices=(0, 1),\n",
        "                            target_goal=4)),\n",
        "                ),\n",
        "            ),\n",
        "            edges=dict(\n",
        "                ant1__cap1=dict(\n",
        "                    extra_observers=[\n",
        "                        dict(observer_type='root_vec', indices=(0, 1)),\n",
        "                    ],\n",
        "                    reward_fns=dict(\n",
        "                        dist=dict(reward_type='root_dist', offset=5)),\n",
        "                    score_fns=dict(dist=dict(reward_type='root_dist')),\n",
        "                ),)),\n",
        "}\n",
        "if env_name in env_descs:\n",
        "  env_desc = env_descs[env_name]\n",
        "  env_fn = composer.create_fn(\n",
        "      env_desc=env_desc, desc_edits=desc_edits)\n",
        "else:\n",
        "  env_fn = composer.create_fn(env_name=env_name)\n",
        "env = env_fn()\n",
        "show_env(env, mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGRizNxK3MtF"
      },
      "outputs": [],
      "source": [
        "#@title Training the custom env\n",
        "num_timesteps_multiplier =   3# @param {type: 'number'}\n",
        "skip_training = False # @param {type: 'boolean'}\n",
        "\n",
        "log_path = output_path\n",
        "if log_path:\n",
        "  log_path = f'{log_path}/training_curves.csv'\n",
        "tab = logger_utils.Tabulator(output_path=log_path,\n",
        "    append=False)\n",
        "\n",
        "# We determined some reasonable hyperparameters offline and share them here.\n",
        "n = num_timesteps_multiplier\n",
        "train_fn = functools.partial(\n",
        "    ppo.train,\n",
        "    num_timesteps=int(50_000_000 * n),\n",
        "    log_frequency=20, reward_scaling=10,\n",
        "    episode_length=1000, normalize_observations=True,\n",
        "    action_repeat=1, unroll_length=5,\n",
        "    num_minibatches=32, num_update_epochs=4,\n",
        "    discounting=0.95, learning_rate=3e-4,\n",
        "    entropy_cost=1e-2, num_envs=2048,\n",
        "    extra_step_kwargs=False, batch_size=1024)\n",
        "\n",
        "times = [datetime.now()]\n",
        "plotdata = {}\n",
        "plotpatterns = ['eval/episode_reward', 'eval/episode_score']\n",
        "\n",
        "def progress(num_steps, metrics, params):\n",
        "  times.append(datetime.now())\n",
        "  plotkeys = []\n",
        "  for key, v in metrics.items():\n",
        "    assert not jnp.isnan(v), f'{key} {num_steps} NaN'\n",
        "    plotdata[key] = plotdata.get(key, dict(x=[], y=[]))\n",
        "    plotdata[key]['x'] += [num_steps]\n",
        "    plotdata[key]['y'] += [v]\n",
        "    if any(x in key for x in plotpatterns):\n",
        "      plotkeys += [key]\n",
        "  if num_steps \u003e 0:\n",
        "    tab.add(num_steps=num_steps, **metrics)\n",
        "    tab.dump()\n",
        "  clear_output(wait=True)\n",
        "  num_figs = max(len(plotkeys), 2)\n",
        "  fig, axs = plt.subplots(ncols=num_figs, figsize=(3.5 * num_figs, 3))\n",
        "  for i, key in enumerate(plotkeys):\n",
        "    if key in plotdata:\n",
        "      axs[i].plot(plotdata[key]['x'], plotdata[key]['y'])\n",
        "    axs[i].set(xlabel='# environment steps', ylabel=key)\n",
        "    axs[i].set_xlim([0, train_fn.keywords['num_timesteps']])\n",
        "  fig.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "if skip_training:\n",
        "  core_env = env_fn()\n",
        "  params, inference_fn = ppo.make_params_and_inference_fn(\n",
        "    core_env.observation_size,\n",
        "    core_env.action_size,\n",
        "    normalize_observations=True)\n",
        "  inference_fn = jax.jit(inference_fn)\n",
        "else:\n",
        "  inference_fn, params, _ = train_fn(\n",
        "    environment_fn=env_fn,\n",
        "    progress_fn=progress)\n",
        "  print(f'time to jit: {times[1] - times[0]}')\n",
        "  print(f'time to train: {times[-1] - times[1]}')\n",
        "  print(f'Saved logs to {log_path}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-0VYySqOEk0"
      },
      "outputs": [],
      "source": [
        "#@title Visualizing a trajectory of the learned inference function\n",
        "eval_seed = 0  # @param {'type': 'integer'}\n",
        "\n",
        "env, states = evaluators.visualize_env(\n",
        "    env_fn=env_fn, inference_fn=inference_fn,\n",
        "    params=params, batch_size=0,\n",
        "    seed = eval_seed, output_path=output_path,\n",
        "    verbose=True,\n",
        ")\n",
        "HTML(html.render(env.sys, [state.qp for state in states]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "name": "composer.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1BCqjiaBc13bQK1gQiEMUQGrxjPTov2EN",
          "timestamp": 1632316642406
        },
        {
          "file_id": "1ZaAO4BS2tJ_03CIXdBCFibZR2yLl6dtv",
          "timestamp": 1630801484981
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
